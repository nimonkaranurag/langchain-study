**LangSmith** Observability

# Know what your agents are really doing

LangSmith Observability gives you complete visibility into agent behavior with tracing, real-time monitoring, alerting, and high-level insights into usage.

[Sign up](https://smith.langchain.com/)[Get a demo](/contact-sales)

Helping top teams ship reliable agents

## Find failures fast with agent tracing

Quickly debug and understand non-deterministic LLM app behavior with tracing. See what your agent is doing step by step —then fix issues to improve latency and response quality.

[Get started tracing your app](https://docs.langchain.com/langsmith/observability)

## Monitor what matters  to the business

Track business-critical metrics like costs, latency, and response quality with live dashboards. Get alerts when issues happen and drill into the root cause.

[See how to create a custom dashboard](https://docs.langchain.com/langsmith/dashboards)

## Discover usage patterns and issues automatically

See clusters of similar conversations to understand what users actually want and quickly find all instances of similar problems to address systemic issues.

[Learn more about Insights](https://docs.langchain.com/langsmith/insights)

## Ready to get visibility into your agents?

LangSmith works with any framework. If you’re already using LangChain or LangGraph, just set one environment variable to get started with tracing your AI application.

[Sign up for free](https://smith.langchain.com/)[Book a demo](/contact-sales)

## Resources for LangSmith Observability

[webinar

##### Get started with LangSmith Tracing](https://www.youtube.com/watch?v=fA9b4D8IsPQ)[DOCS

##### LangSmith Observability concepts](https://docs.langchain.com/langsmith/observability-concepts)[blog

##### LangSmith OTel support](https://blog.langchain.com/end-to-end-opentelemetry-langsmith/)

## FAQs for LangSmith Observability

What frameworks and libraries does LangSmith work with?

LangSmith works with any framework. You can use it with or without our open source frameworks LangChain and LangGraph. [Learn more.](https://docs.langchain.com/langsmith/home)

Does LangSmith support OTel?

Yes, LangSmith supports with OTel to unify your observability stack across services. Your application does not need to be written in Python or Typescript. [See the docs.](https://docs.langchain.com/langsmith/trace-with-opentelemetry)

Can I use LangSmith Observability without LangSmith Evaluation?

Yes. You can use LangSmith Observability with or without Evaluation. For all plan types, you'll get access to both and only pay for what you use.

I can’t have data leave my environment. Can I self-host LangSmith?

Yes, we allow customers to self-host LangSmith on our enterprise plan. We deliver the software to run on your Kubernetes cluster, and data will not leave your environment. For more information, check out our [documentation](https://docs.langchain.com/langsmith/architectural-overview).

Where is my data stored?

When using LangSmith hosted at smith.langchain.com, data is stored in GCP us-central-1. If you’re on the Enterprise plan, we can deliver LangSmith to run on your kubernetes cluster in AWS, GCP, or Azure so that data never leaves your environment. For more information, check out our [documentation](https://docs.smith.langchain.com/self_hosting/kubernetes).

Will LangSmith add latency to my application?

No, LangSmith does not add any latency to your application. In the LangSmith SDK, there’s a callback handler that sends traces to a LangSmith trace collector which runs as an async, distributed process. Additionally, if LangSmith experiences an incident, your application performance will not be disrupted.

Will you train on the data that I send LangSmith?

We will not train on your data, and you own all rights to your data. See LangSmith [Terms of Service](https://www.langchain.com/terms-of-service) for more information.

How much does LangSmith cost?

See our [pricing page](https://www.langchain.com/pricing-langsmith) for more information, and find a plan that works for you.